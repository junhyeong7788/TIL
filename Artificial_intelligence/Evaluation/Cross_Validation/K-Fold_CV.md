# 🚀 K-Fold Cross Validation

### 🎯 주요 키워드

`K-Fold Cross Validation(K-폴드 교차 검증)` : 머신러닝 모델의 성능을 평가하는 데 사용디는 재샘플링(resampling) 방법

- 데이터셋을 여러 개의 하위 집합(폴드)으로 나누고, 모델을 여러 번 훈련하여 일반화 성능을 추정하는 데 활용

---

# 📝 새로 배운 개념

## 🏷 작동 방식

- Dataset을 **K개의 동일한 크기의 폴드(folds)** 로 무작위 분할
- 모델을 K번 훈련하며, 각 반복에서 K-1 개의 폴드를 학습용 데이터로 사용하고, 나머지 1개의 폴드를 검증용 데이터로 사용
- 각 반복에서 모델의 성능 지표(예 : 평균 제곱 오차(MSE), 정확도, F1-score 등)를 기록
- 최종 모델 성능 평가는 **K개의 검증 점수의 평균** 으로 계산
  - $CV(k) = \frac{1}{k} \sum_{i=1}^{K} MSE_i$
  - $MSE_i$ : i번째 폴드에서의 평균 제곱 오차

## 🏷 K값 선택

- K =5, K=10이 가장 많이 사용되는 값
  - 편향(bias)와 분산(variance) 사이의 균형을 맞추기 위해 적절한 K값을 선택
- **K=N (N=데이터셋의 크기)** 인 경우, **Leave-One-Out Cross Validation(LOOCV, 1-제외 교차 검증)** : 각 샘플이 자체 검증 세트가 되어 편향을 최소화하지만, 분산이 커지고 계산 비용이 증가함

## 🏷 K-폴드 CV에서 편향-분산 트레이드오프

- K값이 작을수록 (5 or 10) : 편향이 증가하지만 분산이 줄어듬
- K값이 클수록 (ex: LOOCV) : 편향은 줄어들지만 분산이 증가하며, 계산 비용이 높아진다

## 🏷 장점

- 분산 감소 : 단순한 학습 - 테스트 데이터 분할보다 모델의 성능 변동성을 줄일 수 있음
- 데이터의 효율적인 사용
- 다양한 모델에 적용가능

---

# 💡 적용 및 활용

## 사용 분야

- K-폴드 교차 검증은 모델 성능을 평가하고 **과적합(overfitting)** 을 방지하는 강력한 기법
- **편향과 분산의 균형을 맞출 수 있으며,** 단순한 학습-테스트 분할보다 신뢰성 있는 모델 평가가 가능
- **실무에서 가장 많이 사용하는 값** : 5-Fold, 10-Fold

---

# 🔗 레퍼런스

## 참고 강의/글

- [sklearn으로 교차검증 마스터하기🔥(1) -KFold, Stratified KFold](https://dacon.io/en/codeshare/4546)
