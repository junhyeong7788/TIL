# 🚀 Cross_Validation

### 🎯 주요 키워드

머신러닝 모델의 **일반화 성능** (새로운 데이터에 대한 예측력)을 안정적으로 추정하기 위해, 주어진 데이터셋을 여러 번 반복해서 훈련과 평가를 반복 수행하는 기법

- "데이터를 여러 개의 부분 집합으로 나누고, 이들 줄 일부를 학습에 나머지를 평가에 사용한 뒤 모든 데이터가 평가에 포함되도록 반복" 하는 과정 (`= K번으로 나누고 각각의 학습 모델의 성능을 비교하여 평균 값`)

---

# 📝 새로 배운 개념

## 🏷 Cross_Validation 이란?

- **정의:** 데이터셋을 여러 번의 훈련/검증 단계로 나누어 모델 성능을 객관적으로 평가하려는 방법
- **주요 방법:** K-Fold, Stratified K-Fold, Leave-One-Out, Repeated K-Fold 등

## 🏷 교차 검증을 하는 이유

1. **오버피팅 방지**

- 머신러닝 모델을 만들고 모델의 성능을 높이기 위해 우리는 데이터셋을 학습용 데이터와 테스트용 데이터로 나눈다.
- 하지만 고정된 test set을 가지고 모델의 성능을 확인하고 파라미터를 수정하고 해당 과정을 반복하면, 결국 우리가 만든 모델은 test set에만 잘 동작하는 모델이 된다.
- 실제 다른 데이터에 대한 일반화 성능이 제대로 측정되지 못할 수 있다.

2. **데이터 효율 활용**

- 데이터가 충분히 많지 않은 상황, 한 번의 train/test 분할로 학습에 사용할 수 있는 데이터가 상대적으로 적어지면 학습에 불리함

## 🏷 교차 검증의 효과

- `Train_set`, `Val_set`, `Test_set`
- 더 이상 train_set으로만 학습하는 것이 아니라 val_set으로 평가하면서 하이퍼파라미터를 튜닝하고 모델을 학습할 수 있음
  - 앞에서는 train_set에 대해서만 과적합이 발생할 수 있지만 이번에는 val_set에만 과적합이 될 수 있다.
  - 또한 모델을 평가하는 데 있어서 특정 데이터셋에서만 성능이 잘 나와 test_set에서는 성능이 잘 나오지 않는 경우가 생길 수 있다.
  - 그래서 하나의 검증이 아닌 여러 번의 검증으로 일반적인 모델을 만들고 파라미터를 튜닝하기 위해서 교차검증이 등장

---

# 💡 적용 및 활용

## 사용 분야

- 머신러닝/데이터 사이언스 대회
- 학술 연구 전반

---

# 🔗 레퍼런스

## 참고 강의/글

- [[머신러닝] 교차검증 (Cross Validation)](https://velog.io/@soo_oo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D-Cross-Validation)
- [[머신러닝] 교차검증 (cross validation) - KFold, StratifiedKFold](https://velog.io/@kimjo/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D-cross-validation-KFold-StratifiedKFold-Bayesian-Optimization)
