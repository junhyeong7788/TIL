# 🚀 학습 키워드

## 정의

Boosting 알고리즘 : 다수의 약한 학습기 (Weak Learner)를 순차적으로 결합하여 하나의 강력한 학습기 (Strong Learner)를 만드는 앙상블 학습 기법

## 키워드

- 주요 아이디어 : `이전 모델이 틀린 샘플에 가중치를 부여하여 점진적으로 개선하는 것`
  - 즉, 이전 단계에서 오분류된 데이터에 더 많은 가중치를 부여하여 후속 학습기가 이를 보완하도록 한다.

---

# 📝새로 배운 개념

### 순차적 학습 (Sequential Learning)

- 먼저 간단한 모델(ex: 결정 트리)을 학습 시키고, 이후 모델들은 이전 모델이 잘못 예측했던 데이터에 **더 큰 가중치** 를 부여하여 학습. 이렇게 해서 각 단계마다 이전 모델의 오류를 보완하도록 설계한다.

### 약한 학습기 (Weak Learner)

- 각각의 약한 학습기는 개별적으로는 성능이 미흡할 수 있으나, 여러 모델을 결합해 최종 예측을 도출하면 전반적인 성능이 크게 향상된다.

### 가중치 조정(Weight Updating)

- 각 단계에서 샘플의 가중치를 조정하여 이전 학습기의 약점을 보완
- 오분류된 데이터에 높은 가중치를 부여하여 후속 모델이 더 신경쓰도록 유도함

### Boosting 장단점

- 장점
  - 높은 예측 성능을 보이며, 특히 복잡한 데이터셋에서 강력한 성능을 발휘
  - 과적합에 비교적 강함
  - 다양한 머신러닝 모델과 결합 가능
- 단점
  - 학습 속도가 느림 (순차적 학습 때문)
  - 하이퍼파라미터 튜닝이 어려움
  - 데이터가 노이즈에 민감할 수 있음

---

# ✨

## Boosting 알고리즘의 종류

|     알고리즘      |                                          특징                                          |
| :---------------: | :------------------------------------------------------------------------------------: |
|     AdaBoost      |  틀린 샘플에 높은 가중치를 부여, 각 약한 학습기의 가중치를 조정하여 최종 예측을 수행   |
| Gradient Boosting |          오차를 줄이기 위해 손실함수와 기울기를 이용하여 다음 학습기를 최적화          |
|      XGBoost      |            Gradient Boosting 을 개선한 알고리즘, 규제항 추가, 병렬처리 지원            |
|     LightGBM      |      XGBoost 보다 빠른 속도, 효율적인 메모리 사용, 리프 중심 트리 분할 방식 사용       |
|     CatBoost      | 범주형 데이터 처리에 최적화된 부스팅 프레임워크, target leakage 및 예측 편향 문제 해소 |

## Boosting vs Bagging (대표적인 앙상블 기법)

|      ---       |                         Boosting                         |              Bagging              |
| :------------: | :------------------------------------------------------: | :-------------------------------: |
|   학습 방식    |                 순차적 학습 (Sequential)                 |       병렬 학습 (Parallel)        |
|      목표      |                  이전 모델의 오류 보완                   |            과적합 방지            |
| 대표 알고리즘  | AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost | Random Forest , BaggingClassifier |
| 오류 처리 방식 |              오분류된 데이터에 가중치 증가               |  데이터 샘플링을 통해 분산 감소   |

---

# 💻활용 사례

## 활발한 사용 분야

- ✔ 신용 평가(Credit Scoring): 금융 기관에서 고객의 신용도를 평가하는 데 사용
- ✔ 의료 진단(Medical Diagnosis): 환자의 질병 여부 예측
- ✔ 검색 엔진(Search Ranking): 검색 결과의 랭킹을 조정하는 데 사용
- ✔ 추천 시스템(Recommendation System): 사용자 맞춤형 추천 알고리즘
- ✔ 자연어 처리(NLP): 감성 분석(Sentiment Analysis), 텍스트 분류(Text Classification)

---

# 🔗레퍼런스

## 참고 강의/글

- [LightGBM](https://jaaamj.tistory.com/40)
