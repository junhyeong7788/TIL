> 울산대학교 Ai융합전공, 2024년 4학년 1학기, Ai 정보이론 / 수업 내용 및 추가 학습 서술

# Chain Rule

: 한 쌍의 무작위 변수의 엔트로피는 한 쌍의 엔트로피에 다른 한 쌍의 조건부 엔트로피를 더한 값이다.

- X와 Y의 결합 엔트로피를 X의 엔트로피와 X가 주어졌을 때 Y의 조건부 엔트로피의 합으로 계산할 수 있다.
- 두 개 이상의 확률변수의 결합엔트로피를 계산하는 간단한 방법을 제공하는 것,
- 쉽게 말하면, *여러 사건이 동시에 일어날 때 얼마나 예측하기 어려운지*를 계산하는 공식

- 정리
  ![equation](<https://latex.codecogs.com/svg.image?\huge&space;&space;H(X,Y)=H(X)+H(Y|X)>)
  : joint entropy = entropy + conditional entropy 로 나타낼 수 있다.

  - H(X, Y) : X와 Y의 결합 엔트로피 (두 사건이 동시에 일어날 때 얼마나 예측하기 어려운지)
  - H(X) : X의 엔트로피 (첫 번째 사건이 얼마나 예측하기 어려운지)
  - H(Y|X) : X가 주어졌을 때 Y의 조건부 엔트로피 (첫 번째 사건의 결과를 알고 있을 때 두 번째 사건이 얼마나 예측하기 어려운지)
  - 체인 규칙은 두 사건의 동시 발생 불확실성을 첫 번째 사건의 불확실성과 두 번째 사건의 (첫 번째 사건을 알고 있을 때의) 불확실성의 합으로 계산한다는 것을 의미

- 증명
  ![alt text](<Information Theory Attached file/Pasted image 20240410231714.png>)
  ![alt text](<Information Theory Attached file/Pasted image 20240325193808.png>)
- Corollary
  ![equation](<https://latex.codecogs.com/svg.image?\huge&space;&space;H(X,Y|Z)=H(X|Z)+H(Y|X,Z)>)

ex)
Let (X,Y) have the following joint distribution.
![alt text](<Information Theory Attached file/Pasted image 20240314214046.png>)

# 엔트로피 Chain rule 의 일반형

![alt text](<Information Theory Attached file/Pasted image 20240325200920.png>)
: 체인 규칙은 *n개의 사건의 동시 발생 불확실성*을 첫 번째 사건의 불확실성과 나머지 사건들의 (첫 번재 사건의 결과를 알고 있을 때의) 불확실성의 합으로 계산한다는 것을 의미

# 참조

- [[4. Joint Entropy and Conditional Entropy]]
