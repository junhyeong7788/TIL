# 🚀 학습 키워드

## 키워드

- `순전파` 와 `역전파`

---

# 📝새로 배운 개념

## 순전파 (Forward Propagation)

- 네트워크에 훈련 데이터가 들어올 때 발생, 데이터를 기반으로 예측 값을 계산하기 위해 전체 신경망을 교차해 지나간다.
  - 정의 : 모든 뉴런이 이전 층의 뉴런에서 수신한 정보에 변환 (가중합 및 활성화 함수)을 적용하여 다음 층(은닉층)의 뉴런으로 전송하는 방식
  - 설명 : 네트워크를 통해 입력 데이터를 전달하며, 데이터가 모든 층을 통과하고 모든 뉴런이 계산을 완료하면 그 예측 값은 최종 층(출력층)에 도달
    - 그 다음 손실 함수로 네트워크의 예측 값과 실제 값의 차이(손실, 오차)를 추정
    - 손실 함수 비용이 0에 가깝도록 하기 위해 모델이 훈련을 반복하면서 가중치를 조정
    - 손실(오차)이 계산되면 그 정보는 역으로 전파 된다. `= 역전파`

## 역전파 (Backward Propagation)

- 정의 : 순전파에서 계산된 값 (출력과 중간층 값)을 사용해 손실 함수의 기울기를 계산하고, **이를 통해 모델의 가중치와 바이어스를 업데이트한다.**
- 설명 : 출력층에서 시작된 손실 비용은 은닉층의 모든 뉴런으로 전파되지만, 은닉층의 뉴런은 각 뉴런이 원래 출력에 기여한 상대적 기여도에 따라 (즉, 가중치에 따라) 값이 달라짐
  - 예측값과 실제값 차이를 뉴런의 가중치로 미분한 후 기존 가중치 값에서 뺀다.
  - 이를 `출력층 -> 은닉층 -> 입력층` 순서로 모든 뉴런에 대해 진행하여 계산된 각 뉴런 결과를 또 다시 순전파의 가중치 값으로 사용한다.

---

# 🔗레퍼런스

## 참고 강의/글

- [딥러닝 파이토치 교과서]
