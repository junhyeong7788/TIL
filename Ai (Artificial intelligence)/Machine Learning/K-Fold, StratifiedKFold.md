# ğŸš€ í•™ìŠµ í‚¤ì›Œë“œ

## ì •ì˜
- `K-Fold cross_validation` : Kê°œì˜ ë°ì´í„° í´ë“œ ì„¸íŠ¸ë¥¼ ë§Œë“¤ì–´ Kë²ˆ ë§Œí¼ ê° í´ë“œ ì„¸íŠ¸ì— í•™ìŠµê³¼ ê²€ì¦ í‰ê°€ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•

## í‚¤ì›Œë“œ 
`K-Fold êµì°¨ ê²€ì¦: ë°ì´í„°ë¥¼ Kê°œì˜ í´ë“œë¡œ ë‚˜ëˆ„ì–´ ê° í´ë“œë§ˆë‹¤ í•™ìŠµê³¼ ê²€ì¦ì„ ë°˜ë³µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, ë¶ˆê· í˜•í•œ ë°ì´í„°ì—ì„œëŠ” Stratified K-Foldë¥¼ ì‚¬ìš©í•˜ì—¬ ë ˆì´ë¸” ë¶„í¬ë¥¼ ê· ì¼í•˜ê²Œ ìœ ì§€í•œë‹¤.`

---

# ğŸ“ìƒˆë¡œ ë°°ìš´ ê°œë…

## K-Fold
- Kê°œì˜ ì˜ˆì¸¡ í‰ê°€ë¥¼ êµ¬í–ˆìœ¼ë©´ ì´ë¥¼ í‰ê· í•´ì„œ Kí´ë“œ í‰ê°€ ê²°ê³¼ë¡œ ë°˜ì˜
	- ex : K=5, ì´ 5ê°œì˜ í´ë“œì„¸íŠ¸ì— 5ë²ˆì˜ í•™ìŠµê³¼ ê²€ì¦ í‰ê°€ ë°˜ë³µ ìˆ˜í–‰
- ì‚¬ì´í‚·ëŸ°ì€ KFoldì™€ StratifiedKFold í´ë˜ìŠ¤ë¥¼ í†µí•´ êµì°¨ ê²€ì¦ ë¶„í• ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ ì œê³µ

```python
from sklearn.model_selection import KFold

iris = load_iris()
features = iris.data
label = iris.target
dt_clf = DecisionTreeClassifier(random_state=156)

# 5ê°œì˜ í´ë“œ ì„¸íŠ¸ë¡œ ë¶„ë¦¬í•˜ëŠ” KFold ê°ì²´ì™€ í´ë“œ ì„¸íŠ¸ë³„ ì •í™•ë„ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ê°ì²´ ìƒì„±
kfold = KFold(n_splits=5) # n_splits : int, default=5 (ìµœì†Œ 2ì´ìƒ)
cv_accuracy = []
print('ë¶“ê½ƒë°ì´í„° ì„¸íŠ¸ í¬ê¸° : ', features.shape[0])

import numpy as np
n_iter = 0

# KFold ê°ì²´ì˜ split()ë¥¼ í˜¸ì¶œí•˜ë©´ í´ë“œë³„ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ì˜ ë¡œìš° ì¸ë±ìŠ¤ë¥¼ arrayë¡œ ë°˜í™˜
for train_index, test_index in kfold.split(features):
	# kfold.spilt()ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
	X_train, X_test = features[train_index], features[test_index]
	y_train, y_test = label[train_index], label[test_index]

	#í•™ìŠµ ë° ì˜ˆì¸¡
	dt_clf.fit(X_train, y_train)
	pred = dt_clf.predict(X_test)
	n_iter += 1

	# ë°˜ë³µ ì‹œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì •
	accuracy = np.round(accuracy_score(y_test, pred), 4)
	train_size = X_train.shape[0]
	test_size = X_test.shape[0]

	print('\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ :{1}, í•™ìŠµ ë°ì´í„° í¬ê¸°: {2}, ê²€ì¦ ë°ì´í„° í¬ê¸°: {3}'.format(n_iter, accuracy, train_size, test_size))
	print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤ :{1}'.format(n_iter, test_index))
	cv_accuracy.append(accuracy)

# ê°œë³„ iterationë³„ ì •í™•ë„ë¥¼ í•©í•˜ì—¬ í‰ê·  ì •í™•ë„ ê³„ì‚°
print('\n## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.mean(cv_accuracy) )
```
- ìœ„ ê³¼ì •ì˜ ê²€ì¦ ì„¸íŠ¸ì˜ ì¸ë±ìŠ¤ë¥¼ ë³´ë©´ êµì°¨ê²€ì¦ ì‹œë§ˆë‹¤ split()í•¨ìˆ˜ê°€ ì–´ë–»ê²Œ ì¸ë±ìŠ¤ë¥¼ í• ë‹¹í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤.
## Stratified K-Fold
- ë¶ˆê· í˜•í•œ(imbalanced)ë¶„í¬ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ë°ì´í„° ì§‘í•©ì„ ìœ„í•œ K fold ë°©ì‹
	- ë¶ˆê· í˜•í•œ ë¶„í¬ë„ë¥¼ ê°€ì§„ ë ˆì´ë¸” ë°ì´í„° ì§‘í•© : íŠ¹ì • ë ˆì´ë¸” ê°’ì´ íŠ¹ì´í•˜ê²Œ ë§ê±°ë‚˜ ë§¤ìš° ì ì–´ì„œ ê°’ì˜ ë¶„í¬ê°€ í•œ ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ëŠ” ê²ƒ
	- ë ˆì´ë¸” ë°ì´í„° ì§‘í•©ì´ ì›ë³¸ ë°ì´í„° ì§‘í•©ì˜ ë ˆì´ë¸” ë¶„í¬ë„ë¥¼ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ì œëŒ€ë¡œ ë¶„ë°°í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ì˜ ë¬¸ì œë¥¼ í•´ê²°
	- ì›ë³¸ ë°ì´í„°ì˜ ë ˆì´ë¸” ë¶„í¬ë„ë¥¼ ë¨¼ì € ê³ ë ¤í•œ ë’¤ ì´ ë¶„í¬ì™€ ë™ì¼í•˜ê²Œ í•™ìŠµ ê²€ì¦ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¶„ë°°

```python
# Stratified Kfold
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=3)
n_iter=0

for train_index, test_index in skf.split(iris_df, iris_df['label']):
	n_iter += 1
	label_train= iris_df['label'].iloc[train_index]
	label_test= iris_df['label'].iloc[test_index]
	print('## êµì°¨ê²€ì¦: {0}'.format(n_iter))
	print('í•™ìŠµ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n' , label_train.value_counts())
	print('ê²€ì¦ ë ˆì´ë¸” ë°ì´í„° ë¶„í¬:\n', label_test.value_counts())

df_clf = DecisionTreeClassifier(random_state=156)
skfold = StratifiedKFold(n_splits=3)
n_iter = 0
cv_accuracy = []

# StratifiedKFoldì˜ split()í˜¸ì¶œ ì‹œ ë°˜ë“œì‹œ ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ë„ ì¶”ê°€ ì…ë ¥ í•„ìš”
for train_index, test_index in skfold.split(features, label):

	# split()ìœ¼ë¡œ ë°˜í™˜ëœ ì¸ë±ìŠ¤ë¥¼ ì´ìš©í•´ í•™ìŠµìš©, ê²€ì¦ìš© í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
	X_train, X_test = features[train_index], features[test_index]
	y_train, y_test = label[train_index], label[test_index]

	# í•™ìŠµ ë° ì˜ˆì¸¡
	dt_clf.fit(X_train, y_train)
	pred = dt_clf.predict(X_test)

	# ë°˜ë³µ ì‹œë§ˆë‹¤ ì •í™•ë„ ì¸¡ì •
	n_iter += 1
	accuracy = np.round(accuracy_score(y_test, pred), 4)
	train_size = X_train.shape[0]
	test_size = X_test.shape[0]

	print('\n#{0} êµì°¨ ê²€ì¦ ì •í™•ë„ : {1}, í•™ìŠµ ë°ì´í„° í¬ê¸° : {2}, ê²€ì¦ ë°ì´í„° í¬ê¸° : {3}'.format(n_iter, accuracy, train_size, test_size))
	print('#{0} ê²€ì¦ ì„¸íŠ¸ ì¸ë±ìŠ¤:{1}'.format(n_iter, test_index))
	cv_accuracy.append(accuracy)

# êµì°¨ ê²€ì¦ë³„ ì •í™•ë„ ë° í‰ê·  ì •í™•ë„ ê³„ì‚°
print('\n## êµì°¨ ê²€ì¦ë³„ ì •í™•ë„:', np.round(cv_accuracy, 4))
print('\n## í‰ê·  ê²€ì¦ ì •í™•ë„:', np.round(np.mean(cv_accuracy), 4))
```

- ë¶„ë¥˜ì—ì„œì˜ êµì°¨ê²€ì¦ì€ Stratified Kí´ë“œ ë°©ì‹ìœ¼ë¡œ ë¶„í• ë˜ì–´ì•¼ í•œë‹¤.
	- íšŒê·€ì˜ ê²°ì •ê°’ì€ ì´ì‚°ê°’ í˜•íƒœì˜ ë ˆì´ë¸”ì´ ì•„ë‹ˆë¼ ì—°ì†ëœ ìˆ«ìì´ê¸° ë•Œë¬¸ì— ê²°ì •ê°’ë³„ë¡œ ë¶„í¬ë¥¼ ì •í•˜ëŠ” ì˜ë¯¸ê°€ ì—†ê¸° ë•Œë¬¸ì´ë‹¤.

---
# âœ¨
### êµì°¨ ê²€ì¦ì˜ ê³¼ì • ìš”ì•½
1. í´ë“œ ì„¸íŠ¸ ì„¤ì •
2. for ë£¨í”„ ë°˜ë³µìœ¼ë¡œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
3. ë°˜ë³µì  í•™ìŠµê³¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰, ì˜ˆì¸¡ ì„±ëŠ¥ì„ ë°˜í™˜
4. í´ë“œ ì„¸íŠ¸ë³„ë¡œ ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê· í•˜ì—¬ ìµœì¢… ì„±ëŠ¥ í‰ê°€

---
# ğŸ”—ë ˆí¼ëŸ°ìŠ¤

## ì°¸ê³  ê°•ì˜/ê¸€

- [### êµì°¨ ê²€ì¦(Cross Validation)ì´ë€? êµì°¨ ê²€ì¦ì˜ ì¢…ë¥˜ ë° ì‚¬ìš©ë²•](https://day-to-day.tistory.com/32)
- [[cross-validation]]
