# 분류 알고리즘의 유형별 특징 정리 - Tree 계열의 알고리즘

Decision TreeClassifier (의사결정나무 분류 알고리즘)

Random Forest
- 여러 개의 의사결정나무의 다수결을 통해서 모델의 성능 개선한 기계학습 방법
- 높은 정확도, 의사결정나무의 과적합 문제를 해결, 많은 개수의 독립변수를 다룰 수 있음
- 연산 시간 오래걸림

Ensemble
- Bagging (Bootstrap Aggregating)
	- 1. 랜덤 샘플링, 2. 개별학습, 3. 보팅(voting), 4. 배깅 결과

- Voting
	- 하드보팅 : 다수의 분류기 간 다수결로 최종 class 결정
	- 소프트보팅 : 다수의 분류기 간의 초종 class 확률을 평균하여 결정
	- 일반적으로 하드보팅보다 소프트 보팅의 성능이 더 좋음

- Boosting - (XGBoost, LightGBM model)
	  1. 가중치 반영한 샘플링
	  2. 개별 학습
	  3. 보팅
	  4. 부스팅 결과

Hyperparameter (하이퍼파라미터)
- 학습과정을 제어하는데 사용되는 매개변수
- 자동 업데이트 X, 모델 생성을 위해 사용자가 셋팅해줘야하는 값
- 하이퍼파라미터 설정값에 따라 학습모델의 결과가 달라짐

## Tree의 주요 매개변수
- criterion (기준)
	- 가지 분할의 성능을 평가하는 기준 설정
- max_features ( 최대 특징 )
	- 의사결정나무의 노드분할을 위한 최대 피처 수
	- 기본값은 None, int : 피처의 수, float: 피처의 비율
- max_leaf_nodes ( 최종 노드 )
	- 잎사귀 노드 (leaf)의 최대 개수 (기본값  = None)
- max_depth 변화 ( 최대 깊이 )
	- max_depth의 값을 크게 설정할 수록 학습용 데이터의 성능은 증가하고 테스트용 데이터의 정확도는 증가하다가 어느 시점부터 감소함 (overfitting)

---
# 분류 알고리즘의 유형별 특징 정리 -  KNN, SVM

## K - Nearest Neighbor

```ad-example
1. 그룹 A와 그룹 B
2. 새로운 데이터 입력, 어떤 그룹에 속할까?
3. 가장 가까운 데이터 하나만 보자 -> 크룹 B
4. 가까운 다섯개의 데이터를 보자 -> 그룹 A
-> 3번과 4번에 따라 결과값이 달라진다. 사용자가 k값을 설정
```

## SVM ( Support Vector Machine)
: 주어진 많은 데이터들을 가능한 멀리 두 개의 집단으로 분리시키는 (마진을 최대로 하는) 최적의 초평면을 찾는 분류모델 알고리즘

![[Pasted image 20240227174805.png]]

### 특징
- 데이터가 적을 때 우수함
- 노이즈 데이터의 영향을 크게 받지 않고, 과적합 문제가 적음
- 처리할 데이터양이 늘어나거나 비정형 데이터인 경우, 복잡도 향상되어 활용 어렵다.
- 최적 분류를 위해서 *커널 함수* 및 *매개 변수*에 대한 반복적인 테스트가 필요
- 결과 해석이 어렵고, 학습 시간이 오래걸림

### SVC > C
: SVM 모델이 오류를 어느정도 허용할 것인지를 지정(정규화 강도)
- C값이 클수록 오류 허용 X , 작을 수록 오류 허용 O
- C값이 커짐 : 빨간색과 파란색을 구분하는 경계의 모양이 복잡해짐

### SVC > gamma
: 초평면 상의 결정경계를 얼마나 유연하게 그을 것인지 결정
- gamma값이 클수록 학습데이터 분포에 민감하게 반응하여 결정경계 생성 (과적합 발생 가능성 높다.)
- 작을 수록 덜 민감하여 직선에 가깡누 결정경계를 생성 (과소적합 발생 가능성 높다.)

### SVC > kernel
: 알고리즘에서 사용할 커널 타입
- linear
- rbf : 방사 기저 함수, 가우시안 커널, 무한 차원
- poly : 다항식 커널 함수

---
# 분류 알고리즘의 유형별 특징 정리 - 분류 알고리즘의 평가 방법

## Confusion Matrix
- Classification 모델이 가질 수 있는 결과를 Matrix로 나타낸 것

![[Pasted image 20240227183548.png]]

- Accuracy ( **TP, TN** )
	- 전체 예측에서 (pos나 neg이든 무관하게) 옳은  예측의 비율
	- 분류  모델에서 기본 지표로 사용
- Precision ( **TP** )
	- Positive Predictive Value
	- Positive로 예측 된 것 중 실제로도 Positive인 경우의 비율
- Recall or Sensitivity ( **TP** )
	- True Positive Rate
	- 실제로 Positive 인 것들 중 예측이 Positive로 된 경우의 비율
- F1 Score
	- Precision과 Recall의 조화평균
-> 데이터의 특성때문에 여러가지 평가지표가 존재

## Precision과 Recall의 함정
- Precision 100%
	- 확실하게 Positive라고 생각하는 경우를 Positive라고 예측하고, 나머지는 모두 Negative라고 예측
- Recall 100%
	- 모든 경우를 Positive라고 예측
- F1-score
	- 정밀도와 재현율이 어느 한쪽으로 차우치지 않은 수치를 나타날 때 높은 값이 나타남

# 마무리
- 데이터 분포가 치우친 경우, 정밀도와 재현율을 활용하여 모델 평가
- 정밀도와 재현율은 상충 관계이므로, 문제의 성격에 따라 어느 쪽을 중시해야 하는지도 달라짐