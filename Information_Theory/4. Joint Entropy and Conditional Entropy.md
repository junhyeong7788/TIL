> 울산대학교 Ai융합전공, 2024년 4학년 1학기, Ai 정보이론 / 수업 내용 및 추가 학습 서술

- 엔트로피 역시 확률 사용 그러므로 *결합 엔트로피와 조건부 엔트로피가 존재*한다.
- 엔트로피는 평균 정보량
  - 정보량 : 어떤 사건이 가지고 있는 '놀람의 정도'
  - 일어날 확률이 *적은 사건이 일어났을 때* 사람들은 놀란다.
	  - 따라서 드물게 일어나는 일 일수록 정보량이 크다.
- 엔트로피는 발생가능한 사건들의 *정보량의 평균(기댓값)* 을 낸 것
  - 따라서 평균 놀람의 정도 또는 불확실성으로 생각가능
  - 여러 사건들이 발생할 확률이 비슷할수록 불확실성, 즉 엔트로피는 커진다.
  - 결과를 예측하기 쉬울수록 엔트로피는 작다.

# Joint Entropy

: 두 개 이상의 확률변수들의 결합확률의 엔트로피
- 결합확률 : 두 개이상의 확률변수가 동시에 발생할 확률을 의미한다.
- 쉽게 말하면, 여러 사건이 동시에 일어날 가능성을 나타내는 수치이다.

- 결합엔트로피는 두 개이상의 확률변수가 동시에 얼마나 불확실한지에 대한 지표
- 쉽게 말하면, 여러 사건이 동시에 일어날 때 *얼마나 예측하기 어려운지를 측정하는 값*이라고 생각하면 된다.

- 확률변수 X, Y의 결합엔트로피는 H(X, Y)로 나타난다.

![equation](<https://latex.codecogs.com/svg.image?\huge&space;H(X,Y)=-\sum_{x\epsilon\chi}^{}\sum_{y\epsilon&space;Y}^{}p(x,y)logp(x,y)>)

![equation](<https://latex.codecogs.com/svg.image?\huge&space;=-E[logp(X,Y)]>)

ex) 결합확률분포표와 계산
![alt text](<Information Theory Attached file/Pasted image 20240313184936.png>)
### 결합엔트로피의 특징
- 0과 ∞ 사이의 값을 갖습니다.
- 두 개의 확률 변수가 서로 독립일 때, 결합 엔트로피는 각 변수의 엔트로피의 합과 같습니다.
- 두 개의 확률 변수가 서로 의존적일 때, 결합 엔트로피는 각 변수의 엔트로피의 합보다 작습니다.
# Conditional Entropy

: 특정 사건이 이미 일어났을 때 다른 사건의 불확실성을 나타내는 지표
- 쉽게 말하면, 한 가지 정보를 알고 있을 때 다른 정보가 얼마나 예측하기 어려운지를 측정하는 값이다.

: X가 주어졌을 때 Y의 엔트로피는 H(Y|X)로 표현 / Y가 주어졌을 때 X의 엔트로피는 H(X|Y)로 표현
: 두 확률변수 X,Y가 서로 상관관계가 있을 때, 확률변수 X의 실현값 x를 조건으로 확률변수 Y의 엔트로피를 구해보면 `H[Y|X = x]` 가 된다. 이 값의 X에 대한 기대값을 조건부 엔트로피라고 한다.

![equation](<https://latex.codecogs.com/svg.image?\huge&space;H(Y|X)=\sum_{x\epsilon\chi}^{}p(x)H(Y|X=x)=-\sum_{x\epsilon\chi}^{}p(x)\sum_{y\varepsilon&space;Y}^{}p(y|x)logp(y|x)=-\sum_{x\epsilon\chi}^{}\sum_{y\epsilon&space;Y}^{}p(x,y)logp(y|x)=-E[logp(Y|X)]>)
: H(Y|X) = -Σ P(x) * Σ P(y|x) * log(P(y|x)) -> P(x)는 X의 발생 확률이고, P(y|x)는 X가 x일 때 Y가 y일 확률

- H(Y|X)는 X가 주어졌을 때 Y의 불확실성을 나타낸다.
- H(Y|X)=0 이면 X가 Y를 완전히 결정한다는 의미이다.
- H(Y|X)=H(Y)이면 X가 Y에 대한 정보를 제공하지 않는다는 의미이다.

### 조건부 엔트로피의 특징
- 0과 ∞ 사이의 값을 갖습니다.
- X와 Y가 서로 독립일 때, 조건부 엔트로피는 Y의 엔트로피와 같습니다. / P(y|x) = P(y)
- X와 Y가 서로 의존적일 때, 조건부 엔트로피는 Y의 엔트로피보다 작습니다.


# 주변 확률 질량 함수 ( Marginal Probability Mass Function )

- 두 확률 변수 중에서 하나의 확률변수에 대해서만 확률분포를 나타낸 함수
  ![equation](<https://latex.codecogs.com/svg.image?\huge&space;P_{X}(X)=\sum{y_{i}}P_{XY}(x,y_{i})>)
  ![equation](<https://latex.codecogs.com/svg.image?\huge&space;P_{Y}(Y)=\sum{x_{i}}P_{XY}(x_{i},y)>)

# 조건부 확률 질량 함수
: 특정한 조건이 존재하는 상황에서 어떠한 사건이 발생할 확률

- 조건부 확률 질량 함수 공식
![equation](https://latex.codecogs.com/svg.image?\huge&space;P_{Y|X}(y|x)=\frac{P_{XY}(x,y)}{P_{X}(x)})

- 두개가 동시에 발생할 확률 / x의 주변확률 값

ex) 결합확률분포표와 주변확률, 계산
![alt text](<Information Theory Attached file/Pasted image 20240313190804.png>)

# 참조
- [[3. 이산확률분포]]
- [[6. 독립변수와 종속변수]]
- [[7. 결합확률과 주변확률]]
- [[8. 조건부 확률]]
- [[10. 평균과 기댓값]]
  