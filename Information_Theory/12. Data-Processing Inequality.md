> 울산대학교 Ai융합전공, 2024년 4학년 1학기, Ai 정보이론 / 수업 내용 및 추가 학습 서술

# Markov Chain (강화학습)

: 정보이론의 핵심개념인 데이터 처리 불평등에 대한 설명
: 데이터 처리 불평등은 어떻게 처리하든 변수 X가 변수 Z에 대해 가지고 있는 *정보량은 증가하지 않는다는 것*을 말한다.

- 3개의 랜덤변수가 마르코프 변수 성립

## definition

```
세 개의 RV X,Y,Z는 조건부 분포가 Y에만 의존하고 조건부로 X에 독립적인 경우
그 순서(X → Y → Z)로 마르코프 사슬을 형성한다고 한다.

이 경우 joint PMF는 다음과 같이 작성할 수 있다.
```

- ![alt text](<Information Theory Attached file/Pasted image 20240407211544.png>)

- **데이터 처리 불평등 정의:** 변수 X, Y, Z가 마르코프 체인 (X → Y → Z)을 형성하면 X가 Z에 대해 가지고 있는 정보량은 Y가 X에 대해 가지고 있는 정보량보다 크거나 같다 (`I(X;Z) ≤ I(Y;X)`).
- **마르코프 체인:** Z의 조건부 분포가 Y에만 의존하고 X에 대해 독립적인 경우 (`P(Z|X,Y) = P(Z|Y)`).
- **결론:** 데이터를 어떤 방식으로 처리하든 X가 Z에 대해 가지고 있는 정보량은 증가하지 않습니다.

- 쉽게 설명
  - X는 Y를 통해 Z에 영향을 미칩니다. 즉, X를 알면 Y를 알 수 있고, Y를 알면 Z를 알 수 있습니다.
  - 데이터 처리 과정은 Y를 변형하거나 새로운 변수를 만들 수 있지만, X가 Z에 대해 가지고 있는 정보량은 변하지 않습니다.
  - 예를 들어, 설문 조사에서 응답자의 성별 (X)과 연령 (Y)을 알고 있다고 가정합니다. 연령은 성별에 따라 다를 수 있지만, 성별을 알고 있다고 해서 연령에 대한 정보가 더 많아지는 것은 아닙니다.

# Properties of Markov Chain

- X → Y → Z인 경우에만 X와 Z가 Y로 주어졌을 때 조건부로 독립적이다.
  ![alt text](<Information Theory Attached file/Pasted image 20240407211631.png>)

- X → Y → Z 는 Z → Y → X 을 의미한다.
- 만약에 Z = f(Y)이면, X → Y →Z 이다.

# Data-Processing Inequality

## Theorem

- If X → Y → Z, then I(X;Y) ≥ I(X;Z)

## 증명

- 체인 규칙에 의해, 우리는 두 가지 다른 방법으로 상호 정보를 확장할 수 있다.

  - `I(X;Y,Z) = I(X;Z) + I(X;Y|Z)`
    `= I(X;Y) + I(X;Z|Y)`

- Y가 주어졌을 때 X와 Z는 조건부로 독립이므로,
- `I(X; Z|Y) = 0`이고 `I(X; Y|Z) ≥ 0` 이다.

  - 결론 : `I(X;Y)>=I(X;Z)`

- 등식은 `I(X;Y|Z) = 0`인 경우에만 평등하다, 즉 X → Z → Y인 경우에만 충족되고 `I(Y; Z) ≥ 1(X; Z)`임을 증명할 수 있다.

# Consequences

- If `Z = g(Y)`, then `I(X;Y) ≥ I(X;g(Y)`).

  - 증명 : X → Y → g(Y)는 마르코프 사슬을 이룬다.
  - 따라서 데이터 Y의 함수는 X에 대한 정보를 증가시킬 수 없다.

- If X → Y → Z, then `I(X;Y|Z) ≤ I(X;Y)`.
  - `I(X; Z|Y) = 0`, 마르코프티에 의한, 그리고 `I(X; Z) ≥ 0`에 주목한다.
  - Thus, `I(X; Y|Z) ≤ I(X;Y)`이다.
- 따라서 X와 Y의 의존성은 랜덤 변수 Z의 관찰에 의해 감소(또는 변하지 않음)된다.
- X, Y, Z가 마르코프 사슬을 이루지 않을 때 `I (X;Y|Z) > I (X;Y)`일 수도 있음을 유의하라.

- 예를 들어, X와 Y를 서로 독립적인 페어 바이너리 랜덤 변수라고 하고, `Z = X + Y`라고 하자. 그러면 `I (X; Y) = 0` 이지만 `I (X; Y|Z) =  H (X|Z) - H(X|Y, Z) = H(X|Z) = P(Z = 1)H (X|Z = 1) = ½ bit`이다.
